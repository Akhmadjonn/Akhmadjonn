{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Jse8nGggcR-Q",
        "1nAyg5vHcjYp",
        "3ox07TRwcyG_",
        "_yTQyravkzXx"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3KExXGAFvP-"
      },
      "outputs": [],
      "source": [
        "#Library\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import klib\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score, classification_report\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, StackingRegressor, BaggingRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier, BaggingClassifier,\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D2LYh3oFGgC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling with Missing value"
      ],
      "metadata": {
        "id": "dOIDqC0diSaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Filling\n",
        "\n",
        "for column in data_f.columns:\n",
        "    if data_f[column].isnull().sum()>0:\n",
        "        if data_f[column].dtype=='object':\n",
        "            data_f[column].fillna(data_f[column].mode()[0], inplace=True)\n",
        "        else:\n",
        "            data_f[column].fillna(data_f[column].mean(), inplace=True)\n",
        "\n",
        "data_f.info()"
      ],
      "metadata": {
        "id": "Ol9qIprpGfBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping\n",
        "\n",
        "df = dfdf = df.dropna(subset=['col1', 'col2'])\n"
      ],
      "metadata": {
        "id": "N0ySoyBAIEHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coding"
      ],
      "metadata": {
        "id": "Jse8nGggcR-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_col = df.select_dtypes(include={'object', 'category'}).columns\n",
        "\n",
        "#Label encoding\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "for column in data_f.columns:\n",
        "  data_f[column] = label_encoder.fit_transform(data_f[column])\n"
      ],
      "metadata": {
        "id": "8cX3mZusGsDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get-demus\n",
        "\n",
        "cordinality = df[categorical_col].nunique()\n"
      ],
      "metadata": {
        "id": "wviWkOf9cVmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "encoded_df = pd.get_dummies(df[categorical_col], drop_first=False)\n",
        "df = df.drop(columns=categorical_col)\n",
        "df = pd.concat([df, encoded_df], axis=1)\n",
        "df = df.astype(int)"
      ],
      "metadata": {
        "id": "hQM0n6jgcfWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#One-hot encoding\n",
        "\n",
        "encoder = OneHotEncoder()\n",
        "encoded_array = encoder.fit_transform(df[categorical_col])\n",
        "encoded_df = pd.DataFrame(encoded_array.toarray(), columns=encoder.get_feature_names_out(categorical_col))\n",
        "df = df.drop(columns=categorical_col)\n",
        "df = pd.concat([df, encoded_df], axis=1)"
      ],
      "metadata": {
        "id": "jhcRrziCcakx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Frequency Encoding\n",
        "\n",
        "for col in ['Director', 'Writer', 'Cast']:\n",
        "    df[col + '_freq'] = df[col].map(df[col].value_counts())\n",
        "\n",
        "df.drop(['Director','Writer','Cast'], axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "qYE-vp8Kj5yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target Encoding\n",
        "\n",
        "country_mean = df.groupby('Country of Origin')['Worldwide Gross'].mean()\n",
        "df['Country_Encoded'] = df['Country of Origin'].map(country_mean)\n",
        "\n",
        "df.drop(['Country of Origin','Languages'], axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "z_2rXPntkFUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data monupulation"
      ],
      "metadata": {
        "id": "1nAyg5vHcjYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "if df[col].isnull().sum()>0:\n",
        "  print(f\" Found {df[col].isnull().sum()} non-numerical or missing in 'Price'.\")\n",
        "\n",
        "  df[col].fillna(df[col].mean(), inplace=True)\n",
        "\n",
        "  print('\\nAfter cleanig: ')\n",
        "  print(df[col].head())"
      ],
      "metadata": {
        "id": "ARdS40JpbYxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert object->numerical\n",
        "\n",
        "df[col] = df[col].map({\"Yes\": 1, \"No\": 0})\n"
      ],
      "metadata": {
        "id": "CXc7fQvyfYOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#date -> int/float\n",
        "df_cleaned['Policy Start Date']= pd.to_datetime(df_cleaned['Policy Start Date'], errors='coerce')\n",
        "\n",
        "df_cleaned['Policy Start Year'] = df_cleaned['Policy Start Date'].dt.year\n",
        "df_cleaned['Policy Start Month'] = df_cleaned['Policy Start Date'].dt.month\n",
        "df_cleaned['Policy Start Day'] = df_cleaned['Policy Start Date'].dt.day\n",
        "\n",
        "df_cleaned.drop(columns=['Policy Start Date'], inplace=True)"
      ],
      "metadata": {
        "id": "JLQk8Q4Rsm-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cleaning symbols for numerical columns\n",
        "\n",
        "\n",
        "columns_to_clean = []\n",
        "\n",
        "def clean_numeric_column(column):\n",
        "\n",
        "    if column.dtype != 'object':\n",
        "        column = column.astype(str)\n",
        "    return (\n",
        "        column.str.replace(r'[^\\d.]', '', regex=True).replace('', np.nan)\n",
        "              .astype(float)\n",
        "    )\n",
        "\n",
        "for col in columns_to_clean:\n",
        "    if col in df.columns:\n",
        "        df[col] = clean_numeric_column(df[col])\n",
        "\n",
        "\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "EvMMLCyqhJQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scaling"
      ],
      "metadata": {
        "id": "eK-uzkH8coVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "go0qXqwhaefK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final data prepros"
      ],
      "metadata": {
        "id": "3zBX4v_Atjew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train= klib.data_cleaning(train)\n"
      ],
      "metadata": {
        "id": "ENzXRxpWcrzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=48)"
      ],
      "metadata": {
        "id": "-E-5BdxIt838"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_train, y_train = smote.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "QTwKidkXtjMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "1vu5s1nOctPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression\n",
        "\n",
        "log_reg = LogisticRegression(max_iter=1000,solver='lbfgs')\n",
        "log_reg.fit(x_train, y_train)\n",
        "y_pred = log_reg.predict(x_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "mVr0T34Cc9H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Liner Regression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train,y_train)\n",
        "y_pred = lin_reg.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse:.2f}')\n",
        "print(f'R-squared: {r2:.2f}')"
      ],
      "metadata": {
        "id": "t8dyMWcpkg5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree Classifier\n",
        "\n",
        "d_tree = DecisionTreeClassifier(random_state=42)\n",
        "d_tree.fit(x_train, y_train)\n",
        "y_pred = model.predict(x_test_scaled)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "AMrVoOYadsrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_tree = DecisionTreeRegressor(random_state=42)\n",
        "d_tree.fit(x_train, y_train)\n",
        "y_pred = model.predict(x_test_scaled)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse:.2f}')\n",
        "print(f'R-squared: {r2:.2f}')"
      ],
      "metadata": {
        "id": "cil7r-OHhtgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest Classifier\n",
        "\n",
        "r_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "r_forest.fit(x_train, y_train)\n",
        "y_pred = r_forest.predict(x_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "zl0bWUklebQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_forest = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "r_forest.fit(x_train, y_train)\n",
        "y_pred = r_forest.predict(x_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse:.2f}')\n",
        "print(f'R-squared: {r2:.2f}')"
      ],
      "metadata": {
        "id": "MCuDOmhdlDNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KNeighboorns Classifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)  # k= 5 nearest neighbors\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "kuAylurualv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsRegressor(n_neighbors=5)  # k= 5 nearest neighbors\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse:.2f}')\n",
        "print(f'R-squared: {r2:.2f}')"
      ],
      "metadata": {
        "id": "rPWze9yzlKuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AdaBoost Classifier\n",
        "\n",
        "ada_boost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "ada_boost.fit(x_train, y_train)\n",
        "y_pred = ada_boost.predict(x_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "dRUNCaYGuMTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced ensemble learning techniques"
      ],
      "metadata": {
        "id": "v4EWkmLLvCkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Stacking\n",
        "\n",
        "\n",
        "# Base models\n",
        "base_models = [\n",
        "    ('decision_tree', DecisionTreeClassifier(random_state=42)),\n",
        "    ('random_forest', RandomForestClassifier(random_state=42, n_estimators=100)),\n",
        "]\n",
        "\n",
        "# 1. Stacking\n",
        "stacking_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression(), cv=5)\n",
        "stacking_model.fit(X_train, y_train)\n",
        "stacking_preds = stacking_model.predict(X_test)\n",
        "# Stacking accuracy\n",
        "stacking_accuracy = accuracy_score(y_test, stacking_preds)\n",
        "print(f\"Stacking Accuracy: {stacking_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "PtIS2vBFvKtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Blending\n",
        "\n",
        "X_train_blend, X_val, y_train_blend, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "#Train base models\n",
        "for name, model in base_models:\n",
        "    model.fit(X_train_blend, y_train_blend)\n",
        "\n",
        "val_preds = np.column_stack([model.predict(X_val) for _, model in base_models])\n",
        "\n",
        "\n",
        "meta_model = LogisticRegression()\n",
        "meta_model.fit(val_preds, y_val)\n",
        "\n",
        "test_preds = np.column_stack([model.predict(X_test) for _, model in base_models])\n",
        "blending_preds = meta_model.predict(test_preds)\n",
        "#Blending accuracy\n",
        "blending_accuracy = accuracy_score(y_test, blending_preds)\n",
        "print(f\"Blending Accuracy: {blending_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "tMuQ3WDWvSsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bagging\n",
        "\n",
        "bagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "bagging_model.fit(X_train, y_train)\n",
        "bagging_pred = bagging_model.predict(X_test)\n",
        "bagging_accuracy = accuracy_score(y_test, bagging_pred)\n",
        "print(f\"Bagging Classifier Accuracy: {bagging_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "QZs69iSkvaRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boosting (AdaBoost)\n",
        "\n",
        "boosting_model = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
        "boosting_model.fit(X_train, y_train)\n",
        "boosting_pred = boosting_model.predict(X_test)\n",
        "boosting_accuracy = accuracy_score(y_test, boosting_pred)\n",
        "print(f\"Boosting Classifier (Ada Boosting) Accuracy: {boosting_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "ebOQnth-viQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {
        "id": "3ox07TRwcyG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform K-fold cross-validation (k=5)\n",
        "\n",
        "cv_scores = cross_val_score(model, x, y, cv=5)  # cv=5 means 5-fold cross-validation\n",
        "avg_cv_scores=np.mean(cv_scores)\n",
        "\n",
        "avg_cv_scores"
      ],
      "metadata": {
        "id": "PlHg1nWNIXQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improving"
      ],
      "metadata": {
        "id": "_yTQyravkzXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mutual Score\n",
        "mi_scores = mutual_info_regression(X, y)\n",
        "\n",
        "mi_scores_df = pd.DataFrame(mi_scores, index=X.columns, columns=['MI Score'])\n",
        "mi_scores_df = mi_scores_df.sort_values(by='MI Score', ascending=False)\n",
        "\n",
        "print(mi_scores_df)"
      ],
      "metadata": {
        "id": "Rc7melzAk2VE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_mi_scores(scores):\n",
        "  scores = scores.sort_values(ascending=True)\n",
        "  width = np.arange(len(scores))\n",
        "  ticks = list(scores.index)\n",
        "\n",
        "  plt.barh(width, scores)\n",
        "  plt.yticks(width, ticks)\n",
        "  plt.title(\"Mutual Information Scores\")\n",
        "  plt.xlabel(\"Mutual Information Scores\")\n",
        "  plt.ylabel(\"Features\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plt.figure(dpi=100, figsize=(8, 5))\n",
        "plot_mi_scores(mi_scores_df[\"MI Score\"])\n",
        ""
      ],
      "metadata": {
        "id": "f6SNAGZUk78i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Charts"
      ],
      "metadata": {
        "id": "DAm-oghFfD4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bar chart\n",
        "\n",
        "plt.bar(x, y, width=0.5)\n",
        "plt.title(\"Title\")\n",
        "plt.xlabel(\"X-axis label\")\n",
        "plt.ylabel(\"Y-axis label\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LvOIFXgTfIVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Learning Curve\n",
        "\n",
        "train_sizes, train_scores, val_scores = learning_curve(model, x_train_scaled, y_train, cv=5, scoring='accuracy', train_sizes=[0.1, 0.33, 0.55, 0.78, 1.0])\n",
        "\n",
        "train_mean = train_scores.mean(axis=1)\n",
        "val_mean = val_scores.mean(axis=1)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(train_sizes, train_mean, label='Training Accuracy', marker='o')\n",
        "plt.plot(train_sizes, val_mean, label='Validation Accuracy', marker='o')\n",
        "plt.xlabel('Training Set Size')\n",
        "plt.legend()\n",
        "plt.title('Learning Curves for Random Forest Classifier')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aVh0TXKggOTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Correlation\n",
        "\n",
        "X = df.copy()\n",
        "correlation_matrix = X.corr()\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix[['target']], annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.title(\"Correlation of Features with target\")\n",
        "plt.show()\n",
        "\n",
        "# Check the correlation between all features to spot any potential multicollinearity\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.title(\"Correlation Matrix of Features\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k_-NwO5dgqhI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}